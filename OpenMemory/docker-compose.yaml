name: ascend-ai

x-common-env: &common-env
  LLM_MODEL: meta-llama-3.1-8b-instruct
  EMBEDDER_MODEL: nomic-ai/nomic-embed-text-v1.5-GGUF

services:
  qdrant:
    image: qdrant/qdrant:latest
    restart: unless-stopped
    ports:
      - "6333:6333"
      - "6334:6334"
    networks:
      default:
        aliases:
          - mem0_store
          - qdrant
    volumes:
      - qdrant_data:/qdrant/storage
    healthcheck:
      test: ["CMD-SHELL", "bash -c 'cat < /dev/null > /dev/tcp/localhost/6333'"]
      interval: 10s
      timeout: 5s
      retries: 5

  openmemory:
    build:
      context: .
      dockerfile: Dockerfile.mem0mcp
    container_name: ascend-ai-openmemory-1
    restart: unless-stopped
    ports:
      - "8765:8765"
    environment:
      <<: *common-env
      QDRANT_HOST: qdrant
      QDRANT_PORT: 6333
      OPENAI_API_KEY: lm-studio
      OPENAI_BASE_URL: http://host.docker.internal:1234/v1
      LOG_LEVEL: DEBUG
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - mem0_data:/root/.mem0
    depends_on:
      qdrant:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8765/openapi.json"]
      interval: 60s
      timeout: 5s
      retries: 5
      start_period: 10s

  mem0-configurator:
    image: curlimages/curl:latest
    restart: "no"
    volumes:
      - ./configure_mem0.sh:/configure_mem0.sh
    environment:
      <<: *common-env
    entrypoint: ["/bin/sh", "/configure_mem0.sh"]
    depends_on:
      openmemory:
        condition: service_healthy

volumes:
  qdrant_data:
  mem0_data:
